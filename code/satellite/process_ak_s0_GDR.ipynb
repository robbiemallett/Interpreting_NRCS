{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84026adc-97cf-48ca-b48c-855c254e5aef",
   "metadata": {},
   "source": [
    "# This code on-server at\n",
    "## /home/robbie/uit_mnt/home/romal7177/nrcs/preprocess_ak.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a777e046-c8cb-4c5b-b941-4e8b22305949",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "from netCDF4 import Dataset\n",
    "import numpy as np\n",
    "from scipy.spatial import KDTree\n",
    "import h5py\n",
    "from ll_xy import lonlat_to_xy\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import calendar\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "import tqdm\n",
    "\n",
    "server_dir=''\n",
    "h5_dir = f'{server_dir}/scratch/robbie/nrcs/h5_dir/'\n",
    "\n",
    "cycles = list(np.arange(1,36))+list(np.arange(100,183))\n",
    "cycles = list(np.arange(134,183))\n",
    "\n",
    "for cycle_num in tqdm.tqdm(cycles):\n",
    "\n",
    "    ak_dir = f'{server_dir}/scratch/robbie/robbie_scratch/ftp-access.aviso.altimetry.fr/geophysical-data-record/saral/gdr_f/'\n",
    "    cycle_code = str(cycle_num).zfill(3)\n",
    "    cycle_dir = f'{ak_dir}cycle_{cycle_code}/'\n",
    "\n",
    "    file_list = os.listdir(cycle_dir)\n",
    "\n",
    "    file_list = [x for x in file_list if '.nc' in x]\n",
    "\n",
    "    for file in file_list:\n",
    "        \n",
    "        try:\n",
    "\n",
    "            with Dataset(f'{cycle_dir}{file}') as d:\n",
    "\n",
    "                surf_class = np.array(d['surf_class'])\n",
    "                class_40hz = np.repeat(surf_class[:,np.newaxis],40,axis=1)\n",
    "\n",
    "                data_dict = {'lon':np.array(d['lon_40hz']).flatten(),\n",
    "                             'lat':np.array(d['lat_40hz']).flatten(),\n",
    "                             'pp':np.array(d['peakiness_40hz']).flatten(),\n",
    "                              'sigma0':np.array(d['seaice_sig0_40hz']).flatten(),\n",
    "                              'si_qual':np.array(d['seaice_qual_flag_40hz']).flatten(),\n",
    "                              'lew':np.array(d['ice2_sigmal_40hz']).flatten(),\n",
    "                              'class':class_40hz.flatten(),\n",
    "                            }\n",
    "\n",
    "                df = pd.DataFrame(data_dict)\n",
    "\n",
    "            df = df[df['sigma0']<1000]\n",
    "\n",
    "            df_nh = df[df['lat']>50]\n",
    "\n",
    "            df_sh = df[df['lat']<-50]\n",
    "\n",
    "            key=str(file.split('_')[4])+str(file.split('_')[5])\n",
    "\n",
    "            df_nh.to_hdf(f'{h5_dir}ak_nh_{cycle_code}_jan25.h5',key='nh'+key,mode='a')\n",
    "            df_sh.to_hdf(f'{h5_dir}ak_sh_{cycle_code}_jan25.h5',key='sh'+key,mode='a')\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(cycle_num, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8356df5-122f-471c-b78a-7b353bf0c2e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d477a3-94fb-4bdd-a414-2253d0637f36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9873901e-32ec-45d0-aeff-b7d5d493c6a6",
   "metadata": {},
   "source": [
    "# Code below does daily-gridding of the hdf files onto the relevant ice type data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5039a392-7858-4a4a-b023-8b47b4177ad6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "from netCDF4 import Dataset\n",
    "import numpy as np\n",
    "from scipy.spatial import KDTree\n",
    "from ll_xy import lonlat_to_xy\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import calendar\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import os\n",
    "import pickle\n",
    "import tqdm\n",
    "\n",
    "server_dir = '/home/robbie/uit_mnt'\n",
    "\n",
    "satam_directory = f'{server_dir}/Data/romal7177/ResearchData/IFT/EarthObservation/SatelliteAltimetry/'\n",
    "scratch=f'{server_dir}/scratch/robbie/nrcs/pickles'\n",
    "\n",
    "nh_it_dir=f'{satam_directory}OSISAF Sea Ice Type'\n",
    "f = '2019/12/ice_type_nh_polstere-100_multi_201912201200.nc'\n",
    "x = Dataset(f'{nh_it_dir}/{f}')\n",
    "longrid = np.array(x['lon'])\n",
    "latgrid = np.array(x['lat'])\n",
    "nh_xgrid,nh_ygrid=lonlat_to_xy(longrid,latgrid,hemisphere='n')\n",
    "nh_tree = KDTree(list(zip(nh_xgrid.ravel(),\n",
    "                       nh_ygrid.ravel())))\n",
    "\n",
    "sh_it_dir = f'{server_dir}/scratch/robbie/melsheimer_ice_type'\n",
    "latf = 'south_lat_12km.hdf'\n",
    "sh_lat = Dataset(f'{sh_it_dir}/{latf}')\n",
    "v = list(sh_lat.variables)[0]\n",
    "lat = np.array(sh_lat[v])\n",
    "\n",
    "lonf = 'south_lon_12km.hdf'\n",
    "sh_lon = Dataset(f'{sh_it_dir}/{lonf}')\n",
    "v = list(sh_lon.variables)[0]\n",
    "lon = np.array(sh_lon[v])\n",
    "\n",
    "sh_xgrid,sh_ygrid=lonlat_to_xy(lon,lat,hemisphere='s')\n",
    "sh_tree = KDTree(list(zip(sh_xgrid.ravel(),\n",
    "                       sh_ygrid.ravel())))\n",
    "\n",
    "trees = {'s':sh_tree,'n':nh_tree}\n",
    "grids = {'s':sh_xgrid,'n':nh_xgrid}\n",
    "\n",
    "def get_date_from_key(key):\n",
    "    datestr = key[2:10]\n",
    "    dt = datetime.date(year=int(datestr[:4]),\n",
    "                       month=int(datestr[4:6]),\n",
    "                       day=int(datestr[6:8]))\n",
    "    return dt\n",
    "\n",
    "ak_directory=f'{server_dir}/scratch/robbie/nrcs/h5_dir'\n",
    "ak_files = os.listdir(ak_directory)\n",
    "ak_files = sorted([a for a in ak_files if a[:2]=='ak'])\n",
    "\n",
    "for file in ak_files:\n",
    "    \n",
    "    hem = file.split('_')[1][0]\n",
    "    cycle = int(file.split('_')[2])\n",
    "\n",
    "    print(cycle,hem)\n",
    "\n",
    "    with h5py.File(f'{ak_directory}/{file}','r') as x:\n",
    "        keys = list(x.keys())\n",
    "    dates = np.array([get_date_from_key(key) for key in keys])\n",
    "    dates_mask = np.ones(len(dates))\n",
    "    dates_set = sorted(list(set(dates)))\n",
    "\n",
    "    mean_grids = []\n",
    "\n",
    "    for dt in tqdm.tqdm(dates_set):\n",
    "\n",
    "        mean_vals = np.full(grids[hem].shape,np.nan)\n",
    "\n",
    "        r=np.argwhere(dates==dt)\n",
    "\n",
    "        if r.shape[0]:\n",
    "\n",
    "            keys_on_date = keys[r[0][0]:r[-1][0]]\n",
    "\n",
    "\n",
    "            basic_dict = {(a,b):[] for a,b in itertools.product(np.arange(grids[hem].shape[0]),\n",
    "                                                                np.arange(grids[hem].shape[1]))}\n",
    "\n",
    "            for key in keys_on_date:\n",
    "\n",
    "                df = pd.read_hdf(f'{ak_directory}/{file}',mode='r',key=key)\n",
    "\n",
    "                df = df[df['pp']<5]\n",
    "                df = df[df['lew']<2]\n",
    "\n",
    "                at_x, at_y = lonlat_to_xy(np.array(df['lon']),\n",
    "                                          np.array(df['lat']),\n",
    "                                          hemisphere=hem)\n",
    "\n",
    "                tree = trees[hem]\n",
    "\n",
    "                dist,ind = tree.query(np.array([at_x,at_y]).T)\n",
    "\n",
    "                ind2d = np.unravel_index(ind, grids[hem].shape)\n",
    "\n",
    "                sig0_lin = 10 ** (df['sigma0']/10)\n",
    "\n",
    "                for (a,b,s) in zip(ind2d[0],ind2d[1],sig0_lin):\n",
    "                    basic_dict[(a,b)].append(s)\n",
    "\n",
    "\n",
    "            vals,xscat,yscat = [],[],[]\n",
    "\n",
    "            for key, value in basic_dict.items():\n",
    "\n",
    "\n",
    "                if value:\n",
    "                    mean_vals[key[0],key[1]] = np.nanmean(value)\n",
    "\n",
    "        mean_grids.append(mean_vals)\n",
    "\n",
    "\n",
    "    pickle.dump(mean_grids,open(f'{scratch}/ak_{cycle}_{hem}h.p','wb'))\n",
    "    pickle.dump(dates_set,open(f'{scratch}/ak_{cycle}_{hem}h_dates.p','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "664278fe-b06d-4c46-8c41-01fd2ed2d6dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hem='n'\n",
    "pickles = os.listdir(f'{scratch}')\n",
    "pickles = sorted([x for x in pickles if ((x[:2]=='ak')&(f'{hem}h_dates.p' in x))])\n",
    "\n",
    "\n",
    "dates_dict = {}\n",
    "for p in pickles[:]:\n",
    "    \n",
    "    print(p)\n",
    "    \n",
    "    dates_set = pickle.load(open(f'{scratch}/{p}','rb'))\n",
    "    \n",
    "    dates_dict[p]=dates_set\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea6d1ae-266c-4029-a76c-2d5d4fcca782",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f4c187-00a3-406c-b682-dbdba5ca6590",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae0a5db-81ac-4123-a989-6a0caa08ba36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed23ee9-d490-475d-a2e4-73ca2a2a75ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4561e3ea-54f3-47de-b6a8-4d7ecd50d669",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311a8c6e-ec45-417a-a249-66bfb18ae865",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695be07f-4a49-46d6-907a-ae59e2af1755",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52162e7-470e-4839-8258-1aa10e700bbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "302cd995-d413-4ed7-9055-66d59808ee94",
   "metadata": {},
   "source": [
    "# Old code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6f2106-e758-42ed-9a05-34722074e7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prep month year pairs\n",
    "\n",
    "winter_months=[1,2,3,4,10,11,12]\n",
    "top_data = {}\n",
    "\n",
    "mon_yr_pairs = []\n",
    "\n",
    "for year in np.arange(2019,2023):\n",
    "    for month in winter_months:\n",
    "        mon_yr_pairs.append((year,month))\n",
    "for month in [10,11,12]:\n",
    "    mon_yr_pairs.append((2018,month))\n",
    "for month in [1,2,3,4]:\n",
    "    mon_yr_pairs.append((2023,month))\n",
    "    \n",
    "# Run code\n",
    "\n",
    "for year,month in mon_yr_pairs:\n",
    "    \n",
    "    mean_grids = []\n",
    "\n",
    "    days_in_month = calendar.monthrange(year,month)[1]\n",
    "\n",
    "    for day in np.arange(1,days_in_month+1):\n",
    "        print(day)\n",
    "        date = datetime.date(year,month,day)\n",
    "\n",
    "        # Format it into a string\n",
    "        date_str_ak = f'{date.year}_{str(date.month).zfill(2)}_{str(date.day).zfill(2)}'\n",
    "\n",
    "        ak_files_on_day = [x for x in ak_files if date_str_ak in x]\n",
    "\n",
    "        basic_dict = {(a,b):[] for a,b in itertools.product(np.arange(xgrid.shape[0]),\n",
    "                                                            np.arange(xgrid.shape[1]))}\n",
    "\n",
    "        for f in ak_files_on_day:\n",
    "\n",
    "            ak = scipy.io.loadmat(f'{ak_directory}/{f}')\n",
    "            PP = ak['parameters'][:,20]\n",
    "            lew = ak['parameters'][:,16]/(2.381e-9)\n",
    "            at_lons = np.array(ak['lon'][:,0])\n",
    "            at_lats = np.array(ak['lat'][:,0])\n",
    "            sig0db = np.array(ak['sig0'][:,0])\n",
    "            sig0_lin = 10 ** (sig0db/10)\n",
    "\n",
    "            df = pd.DataFrame({'lon':at_lons,\n",
    "                               'lat':at_lats,\n",
    "                               'lew':lew,\n",
    "                               'PP':PP,\n",
    "                               'sig0':sig0_lin})\n",
    "            df.dropna(inplace=True)\n",
    "        #     # Supp of https://doi.org/10.1002/2015GL064823\n",
    "            df = df[df['lew']<2]\n",
    "            df = df[df['PP']<5]\n",
    "\n",
    "\n",
    "\n",
    "            at_x, at_y = lonlat_to_xy(np.array(df['lon']),\n",
    "                                      np.array(df['lat']),\n",
    "                                      hemisphere='n')\n",
    "            dist,ind = tree.query(np.array([at_x,at_y]).T)\n",
    "\n",
    "            ind2d = np.unravel_index(ind, xgrid.shape)\n",
    "\n",
    "            for (a,b,s) in zip(ind2d[0],ind2d[1],df['sig0']):\n",
    "                basic_dict[(a,b)].append(s)\n",
    "\n",
    "        vals,xscat,yscat = [],[],[]\n",
    "\n",
    "        mean_vals = np.full(xgrid.shape,np.nan)\n",
    "        for key, value in basic_dict.items():\n",
    "\n",
    "\n",
    "            if value:\n",
    "                mean_vals[key[0],key[1]] = np.nanmean(value)\n",
    "\n",
    "        mean_grids.append(mean_vals)\n",
    "\n",
    "    pickle.dump(mean_grids,open(f'{scratch}ak_{month}_{year}.p','wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
